{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "_You are currently looking at **version 1.1** of this notebook. To download notebooks and datafiles, as well as get help on Jupyter notebooks in the Coursera platform, visit the [Jupyter Notebook FAQ](https://www.coursera.org/learn/python-text-mining/resources/d9pwm) course resource._\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "\n",
    "In this assignment, you'll be working with messy medical data and using regex to extract relevant infromation from the data. \n",
    "\n",
    "Each line of the `dates.txt` file corresponds to a medical note. Each note has a date that needs to be extracted, but each date is encoded in one of many formats.\n",
    "\n",
    "The goal of this assignment is to correctly identify all of the different date variants encoded in this dataset and to properly normalize and sort the dates. \n",
    "\n",
    "Here is a list of some of the variants you might encounter in this dataset:\n",
    "* 04/20/2009; 04/20/09; 4/20/09; 4/3/09\n",
    "* Mar-20-2009; Mar 20, 2009; March 20, 2009;  Mar. 20, 2009; Mar 20 2009;\n",
    "* 20 Mar 2009; 20 March 2009; 20 Mar. 2009; 20 March, 2009\n",
    "* Mar 20th, 2009; Mar 21st, 2009; Mar 22nd, 2009\n",
    "* Feb 2009; Sep 2009; Oct 2010\n",
    "* 6/2008; 12/2009\n",
    "* 2009; 2010\n",
    "\n",
    "Once you have extracted these date patterns from the text, the next step is to sort them in ascending chronological order accoring to the following rules:\n",
    "* Assume all dates in xx/xx/xx format are mm/dd/yy\n",
    "* Assume all dates where year is encoded in only two digits are years from the 1900's (e.g. 1/5/89 is January 5th, 1989)\n",
    "* If the day is missing (e.g. 9/2009), assume it is the first day of the month (e.g. September 1, 2009).\n",
    "* If the month is missing (e.g. 2010), assume it is the first of January of that year (e.g. January 1, 2010).\n",
    "* Watch out for potential typos as this is a raw, real-life derived dataset.\n",
    "\n",
    "With these rules in mind, find the correct date in each note and return a pandas Series in chronological order of the original Series' indices.\n",
    "\n",
    "For example if the original series was this:\n",
    "\n",
    "    0    1999\n",
    "    1    2010\n",
    "    2    1978\n",
    "    3    2015\n",
    "    4    1985\n",
    "\n",
    "Your function should return this:\n",
    "\n",
    "    0    2\n",
    "    1    4\n",
    "    2    0\n",
    "    3    1\n",
    "    4    3\n",
    "\n",
    "Your score will be calculated using [Kendall's tau](https://en.wikipedia.org/wiki/Kendall_rank_correlation_coefficient), a correlation measure for ordinal data.\n",
    "\n",
    "*This function should return a Series of length 500 and dtype int.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dates.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c687f6d77eda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dates.txt'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dates.txt'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "doc = []\n",
    "with open('dates.txt') as file:\n",
    "    for line in file:\n",
    "        doc.append(line)\n",
    "\n",
    "df = pd.Series(doc)\n",
    "df.head(10)\n",
    "\n",
    "print(len(df))\n",
    "for line in df:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206\n",
      "['03/25/93', '6/18/85', '2/6/96', '10/24/89', '3/7/86', '4/09/75', '8/01/98', '1/26/72', '5/24/1990', '1/25/2011', '4/12/82', '7/21/98', '10/21/79', '3/03/90', '2/11/76', '07/25/1984', '4-13-82', '9/22/89', '9/02/76', '9/12/71', '10/24/86', '03/31/1985', '7/20/72', '4/12/87', '06/20/91', '5/12/2012', '3/15/83', '2/14/73', '5/24/88', '7/27/1986', '1-14-81', '7-29-75', '8/14/94', '4/13/2002', '8/16/82', '2/15/1998', '7/15/91', '06/12/94', '9/17/84', '2/28/75', '6/13/92', '7/11/71', '12/26/86', '10/11/1987', '3/14/95', '12/01/73', '08/20/1982', '7/24/95', '8/06/83', '02/22/92', '6/28/87', '07/29/1994', '08/11/78', '10/29/91', '7/6/91', '24', '7/04/82', '4-13-89', '4/12/74', '09/19/81', '9/6/79', '12/5/87', '01/05/1999', '4/22/80', '10/04/98', '09/14/2000', '5/18/71', '8/09/1981', '6/05/93', '12/8/82', '8/26/89', '10/13/95', '4/19/91', '9/20/76', '12/08/1990', '4/11/1974', '7/18/86', '3/31/91', '5/13/72', '011/14/83', '8/16/92', '10/05/97', '07/18/2002', '9/22/82', '2/24/74', '2/11/2006', '7/20/2011', '6/17/95', '6/10/72', '12/15/92', '12/8/97', '4/05/89', '12/04/87', '07/17/92', '12/22/98', '10/02/96', '11/05/90', '5/04/77', '2/27/96', '06 May 1972', '25 Oct 1987', '14 Oct 1996', '30 Nov 2007', '14 Jan 1981', '11 February 1985', '14 Feb 1995', '30 May 2016', '22 Jan 1996', '14 Oct 1992', '18 Oct 1999', '11 Nov 2004', '30 May 2001', '09 Sep 1989', '12 March 1980', '22 June 1990', '28 Sep 2015', '13 Jan 1972', '06 Mar 1974', '10 Oct 1974', '26 May 1974', '23 Aug 2000', '19 Oct 2016', '29 Jan 1994', '11 Nov 1996', '01 Oct 1979', '44', '04 Oct 1972', '18 Oct 2006', '22', '15 Jun 1985', '18 August 1995', '11 Nov 2002', '13 Oct 2016', '14 Jan 2008', '12 March 2004', '30 Nov 1972', '06 May 1993', 'April 11, 1990', 'July 26, 1978', 'May 15, 1989', 'September 06, 1995', 'Mar. 10, 1976', 'September 01, 2012', 'July 25, 1983', 'August 11, 1989', 'April 17, 1992', 'July 11, 1997', 'Nov 11, 1988', 'May 14, 1989', 'Oct 18, 1980', 'May 15, 1998', 'July 25, 1998', 'June 15, 1972', 'September. 15, 2011', '50', 'December 1998', 'September 1999', 'April 1986', 'AFeb 1977', 'February 1983', 'March 1974', '50', '6/1998', '10/1973', '9/2005', '12/2005', '5/1987', '5/2004', '10/1997', '3/1981', '12/2008', '12/1975', '1/1978', '06/1973', '2/1999', '8/2009', '7/1989', '7/2009', '2/2009', '08/1988', '4/2007', '4/2012', '2/1977', '8/2008', '2/1983', '10/1986', '12/1994', '8/2010', '11/2016', '2/1973', '4/1973', '11/1982', '06/1981', '10/1978', 'Since 10', '6/1989', '9/1980', '9/1992', '7/1981', '5/2010', '1/1994', '7/1991', '7/1982', '1989', '1979', '2008']\n"
     ]
    }
   ],
   "source": [
    "date_pattern = re.compile('\\d*\\s\\w*\\s\\d{2,4}|'\n",
    "                          '((\\d*[/-])?\\d*[/-])?\\d{2,4}|'\n",
    "                          '[JFMASOND]\\w*(\\.?\\s\\d*,?)?\\s\\d{1,4}\n",
    "                          )\n",
    "\n",
    "def group_structure_info(text, regex):\n",
    "    structure_info_to_remove = []\n",
    "    for line in text:\n",
    "        s_i = regex.match(line)\n",
    "        if s_i != None:\n",
    "            structure_info_to_remove.append(s_i.group())\n",
    "    return structure_info_to_remove\n",
    "\n",
    "print(len(group_structure_info(df, date_pattern)))\n",
    "print(group_structure_info(df, date_pattern))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def date_sorter():\n",
    "    \n",
    "    # Your code here\n",
    "    \n",
    "    return # Your answer here"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-text-mining",
   "graded_item_id": "LvcWI",
   "launcher_item_id": "krne9",
   "part_id": "Mkp1I"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
